{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c11545",
   "metadata": {},
   "source": [
    "\n",
    "# Bank Marketing — End‑to‑End Classification Workflow (LogReg & LightGBM + SMOTE)\n",
    "\n",
    "This notebook walks through a complete, **explainable** modeling workflow for the classic Bank Marketing dataset.\n",
    "It covers:\n",
    "\n",
    "1. Loading the data and inspecting class balance  \n",
    "2. Preprocessing (scaling numeric features, one‑hot encoding categorical features)  \n",
    "3. Train/test split with stratification  \n",
    "4. A **Logistic Regression** pipeline with threshold tuning and evaluation  \n",
    "5. Batch scoring a second file (`bank.csv`)  \n",
    "6. A **LightGBM** model trained on **SMOTE**-balanced data, with a recall‑aware threshold\n",
    "\n",
    "Each code cell is heavily commented to explain *what* the command does and *why* it's used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f6ff9",
   "metadata": {},
   "source": [
    "\n",
    "> **Optional (Colab/fresh env):** If you're running this in a new environment, you may need to install dependencies.\n",
    "Uncomment and run the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Uncomment to install if needed\n",
    "# !pip install pandas numpy scikit-learn seaborn matplotlib lightgbm imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60155b80",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Imports & Global Settings\n",
    "\n",
    "We import the core scientific Python stack and ML libraries.  \n",
    "- `pandas`/`numpy` for data handling  \n",
    "- `scikit-learn` (preprocessing, models, metrics, pipeline)  \n",
    "- `seaborn`/`matplotlib` for quick visual diagnostics  \n",
    "- `lightgbm` for gradient boosting  \n",
    "- `imblearn` for **SMOTE** (oversampling minority class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd760be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries — used for visualization/diagnostics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing + modeling\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "# Gradient boosting + Oversampling\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e774ac0c",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Load Dataset\n",
    "\n",
    "We read the **Bank Marketing** dataset (`bank-full.csv`) which is typically in `;`-separated (semicolon) format.  \n",
    "- `sep=\";\"` ensures correct parsing.  \n",
    "- We print the shape and the first few rows to verify loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e80ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the training dataset (adjust if needed for your environment)\n",
    "dataset_path = \"/content/bank-full.csv\"\n",
    "\n",
    "# Load data; the dataset uses semicolons as delimiters\n",
    "data = pd.read_csv(dataset_path, sep=\";\")\n",
    "\n",
    "print(\"Dataset Shape:\", data.shape)\n",
    "print(\"\\nPreview of raw dataset (first 5 rows):\")\n",
    "display(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecaae27",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Inspect Target Distribution (Class Balance)\n",
    "\n",
    "The target column **`y`** indicates whether the client subscribed to a term deposit:\n",
    "- `\"yes\"` → positive class (1)  \n",
    "- `\"no\"` → negative class (0)\n",
    "\n",
    "We compute **relative frequencies** (`normalize=True`) to understand class imbalance.  \n",
    "This informs decisions like **class weights**, **SMOTE**, and **threshold tuning**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15634ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Current Class Balance (proportions):\")\n",
    "class_balance = data['y'].value_counts(normalize=True)\n",
    "display(class_balance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51b1696",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Encode Target as Numeric\n",
    "\n",
    "Most ML estimators expect numeric targets. We map:\n",
    "- `yes → 1`\n",
    "- `no → 0`\n",
    "\n",
    "We also quickly re‑preview the data to confirm the change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bc60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['y'] = data['y'].map({'yes': 1, 'no': 0})\n",
    "print(\"Unique values in y after mapping:\", data['y'].unique())\n",
    "display(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c872f20",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Separate Feature Types (Categorical vs Numeric)\n",
    "\n",
    "We identify:\n",
    "- **Categorical columns** (`dtype=object`) → need one‑hot encoding  \n",
    "- **Numeric columns** (`dtype number`) → often benefit from scaling\n",
    "\n",
    "We exclude the target `y` from the numeric list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "num_cols = data.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Remove the target from features\n",
    "if 'y' in num_cols:\n",
    "    num_cols.remove('y')\n",
    "\n",
    "print(\"Categorical columns:\", cat_cols)\n",
    "print(\"Numeric columns:\", num_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa43161",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Preprocessing Pipeline (`ColumnTransformer`)\n",
    "\n",
    "We build a **single transformer** that will handle both numeric and categorical features:\n",
    "\n",
    "- `StandardScaler` on numeric columns: centers/scales features for models sensitive to feature magnitude.  \n",
    "- `OneHotEncoder` on categorical columns: creates binary indicator columns per category.\n",
    "\n",
    "**Why `drop=\"first\"`?**  \n",
    "- It drops one category per feature to avoid perfect multicollinearity (useful for linear models like Logistic Regression).\n",
    "\n",
    "**Why `handle_unknown=\"ignore\"`?**  \n",
    "- Avoids errors at inference if a previously unseen category appears; the encoder will emit zeros for it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), cat_cols),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa00567",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Train/Test Split (Stratified)\n",
    "\n",
    "We split data into **train (80%)** and **test (20%)** while **preserving class proportions** using `stratify=y`.\n",
    "This ensures fair evaluation on the imbalanced dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c3e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop('y', axis=1)  # Features (all columns except the target)\n",
    "y = data['y']               # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y,  # preserves original % of positives/negatives\n",
    ")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_train:\", X_train.shape, \"  X_test:\", X_test.shape)\n",
    "print(\"  y_train:\", y_train.shape, \"  y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4720f7c",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Logistic Regression Pipeline\n",
    "\n",
    "We create a **composed pipeline** that first applies the **preprocessor** and then fits a **Logistic Regression** classifier.\n",
    "\n",
    "Key hyperparameters:  \n",
    "- `class_weight=\"balanced\"`: tells the model to weight minority class more heavily, countering imbalance.  \n",
    "- `solver=\"saga\"`: efficient on large/sparse one‑hot matrices; supports L1/L2 regularization.  \n",
    "- `C=0.8`: inverse of regularization strength (smaller → stronger regularization).  \n",
    "- `max_iter=400`: ensures convergence.\n",
    "\n",
    "We use a **custom decision threshold** (`0.55`) on predicted probabilities to trade off precision vs recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the classifier\n",
    "lr_model = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=400,\n",
    "    solver='saga',\n",
    "    C=0.8,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# Assemble the full pipeline\n",
    "pipeline_lreg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', lr_model),\n",
    "])\n",
    "\n",
    "# Train\n",
    "pipeline_lreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class\n",
    "y_prob_lr = pipeline_lreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Choose a custom threshold (tune using PR/ROC analysis as needed)\n",
    "threshold_lr = 0.55\n",
    "y_pred_lr = (y_prob_lr >= threshold_lr).astype(int)\n",
    "\n",
    "print(\"\\n--- Logistic Regression: Test Metrics ---\")\n",
    "print(\"Accuracy :\", round(accuracy_score(y_test, y_pred_lr), 4))\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred_lr), 4))\n",
    "print(\"Recall   :\", round(recall_score(y_test, y_pred_lr), 4))\n",
    "print(\"ROC AUC  :\", round(roc_auc_score(y_test, y_prob_lr), 4))\n",
    "\n",
    "print(\"\\nF1 Score:\", round(f1_score(y_test, y_pred_lr), 4))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f7947",
   "metadata": {},
   "source": [
    "\n",
    "### Confusion Matrix — Logistic Regression\n",
    "\n",
    "The confusion matrix summarizes correct and incorrect predictions.\n",
    "- Rows = **Actual** class  \n",
    "- Columns = **Predicted** class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7eb2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "plt.figure(figsize=(4.5, 4))\n",
    "sns.heatmap(cm_lr, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix — Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d80f7",
   "metadata": {},
   "source": [
    "\n",
    "### Precision & Recall vs Threshold — Logistic Regression\n",
    "\n",
    "This curve shows how **precision** and **recall** change as we vary the probability threshold.  \n",
    "Use it to pick a threshold that fits your business objective (e.g., maximize recall with a minimum precision).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13159a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precisions_lr, recalls_lr, thresholds_lr = precision_recall_curve(y_test, y_prob_lr)\n",
    "\n",
    "plt.figure(figsize=(7, 4.5))\n",
    "plt.plot(thresholds_lr, precisions_lr[:-1], label='Precision')\n",
    "plt.plot(thresholds_lr, recalls_lr[:-1], label='Recall')\n",
    "plt.axvline(x=threshold_lr, color='red', linestyle='--', label='Selected Threshold')\n",
    "plt.title('Precision/Recall vs Threshold — Logistic Regression')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913fe1fa",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Batch Scoring on Another File (`bank.csv`)\n",
    "\n",
    "We load a second file (same schema) and score it with the **trained logistic regression pipeline**.  \n",
    "- We drop the target column `y` from features and keep it separately (if present) to check actual vs predicted.  \n",
    "- The **same preprocessing** learned on the training data is applied automatically by the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to batch file (adjust as needed)\n",
    "batch_path = \"/content/bank.csv\"\n",
    "\n",
    "# Read batch input (semicolon-delimited as well)\n",
    "batch_input = pd.read_csv(batch_path, sep=\";\")\n",
    "\n",
    "# Keep a copy of actuals if `y` exists; map to numeric for comparison\n",
    "y_actual = None\n",
    "if 'y' in batch_input.columns:\n",
    "    y_actual = batch_input['y'].map({'yes': 1, 'no': 0})\n",
    "    batch_features = batch_input.drop('y', axis=1)\n",
    "else:\n",
    "    batch_features = batch_input.copy()\n",
    "\n",
    "# Predict probabilities and hard labels with the same threshold\n",
    "batch_prob_lr = pipeline_lreg.predict_proba(batch_features)[:, 1]\n",
    "batch_pred_lr = (batch_prob_lr >= threshold_lr).astype(int)\n",
    "\n",
    "# Assemble results for inspection\n",
    "results_lr = batch_features.copy()\n",
    "if y_actual is not None:\n",
    "    results_lr['Actual'] = y_actual\n",
    "results_lr['Predicted'] = batch_pred_lr\n",
    "results_lr['Probability'] = batch_prob_lr\n",
    "\n",
    "print(\"Batch results (first 10 rows):\")\n",
    "display(results_lr.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922a3b1c",
   "metadata": {},
   "source": [
    "\n",
    "## 10) LightGBM with SMOTE (on Preprocessed Features)\n",
    "\n",
    "Why this detour? **SMOTE works in numeric feature space**, so we must first transform the raw features using the **same preprocessor** as before. Steps:\n",
    "\n",
    "1. **Fit** the `preprocessor` on `X_train` and **transform** both train and test to numeric matrices.  \n",
    "2. Apply **SMOTE** to oversample the minority class **only on the training fold** (never on test).  \n",
    "3. Train a **LightGBM** classifier on the resampled training data.  \n",
    "4. Tune decision **threshold** to achieve at least a target recall (here, `≥ 0.70`) while maximizing precision among those thresholds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36276166",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Transform raw features to numeric matrices\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)  # fits encoders/scalers on training data\n",
    "X_test_transformed  = preprocessor.transform(X_test)       # applies the learned transforms to test data\n",
    "\n",
    "print(\"Shape after preprocessing (train):\", X_train_transformed.shape)\n",
    "\n",
    "# 2) Apply SMOTE on the transformed training data ONLY\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "print(\"\\nBefore SMOTE:\\n\", y_train.value_counts())\n",
    "print(\"\\nAfter SMOTE:\\n\", y_train_res.value_counts())\n",
    "\n",
    "# 3) Train LightGBM on the resampled training data\n",
    "lgb_model = LGBMClassifier(\n",
    "    class_weight='balanced',  # can help if residual imbalance or misclassification costs remain\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=10,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "lgb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 4) Predict probabilities on the untouched test set\n",
    "y_prob_lgb = lgb_model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "# Compute precision/recall vs thresholds\n",
    "precisions_lgb, recalls_lgb, thresholds_lgb = precision_recall_curve(y_test, y_prob_lgb)\n",
    "\n",
    "# We want recall >= 0.70, and among those thresholds, pick the one with the highest precision.\n",
    "# thresholds_lgb has length len(precisions_lgb)-1; compare only up to that length.\n",
    "mask = (recalls_lgb[:-1] >= 0.70)\n",
    "\n",
    "if mask.any():\n",
    "    # Among valid thresholds (recall >= 0.70), choose index with max precision\n",
    "    candidate_precisions = precisions_lgb[:-1] * mask\n",
    "    best_idx = int(np.argmax(candidate_precisions))\n",
    "    optimal_threshold = float(thresholds_lgb[best_idx])\n",
    "else:\n",
    "    # Fallback: if no threshold reaches the desired recall, use Youden's J best ROC point\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_test, y_prob_lgb)\n",
    "    youden = tpr - fpr\n",
    "    optimal_threshold = float(roc_thresholds[int(np.argmax(youden))])\n",
    "    print(\"Note: No threshold achieved recall >= 0.70; using ROC Youden's J threshold instead.\")\n",
    "\n",
    "print(\"Optimal Threshold (LightGBM):\", optimal_threshold)\n",
    "\n",
    "y_pred_lgb = (y_prob_lgb >= optimal_threshold).astype(int)\n",
    "\n",
    "print(\"\\n--- LightGBM + SMOTE: Test Metrics ---\")\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred_lgb), 4))\n",
    "print(\"Recall   :\", round(recall_score(y_test, y_pred_lgb), 4))\n",
    "print(\"ROC AUC  :\", round(roc_auc_score(y_test, y_prob_lgb), 4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_lgb = confusion_matrix(y_test, y_pred_lgb)\n",
    "plt.figure(figsize=(4.5, 4))\n",
    "sns.heatmap(cm_lgb, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix — LightGBM + SMOTE\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987f3369",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Notes & Caveats\n",
    "\n",
    "- **Thresholds drive the precision/recall trade‑off.** Always pick them based on business cost/benefit.  \n",
    "- **Do not apply SMOTE to the test set.** It should simulate real‑world data.  \n",
    "- Using both **`class_weight='balanced'`** and **SMOTE** is acceptable, but consider your metric and data;\n",
    "  sometimes class weights alone or SMOTE alone is preferable — validate via cross‑validation.  \n",
    "- For production, wrap preprocessing and models into a unified pipeline (e.g., `Pipeline` or `skops` artifacts)\n",
    "  and persist them to versioned storage.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
